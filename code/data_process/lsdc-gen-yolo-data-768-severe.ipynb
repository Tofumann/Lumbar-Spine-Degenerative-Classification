{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"},{"sourceId":9195731,"sourceType":"datasetVersion","datasetId":5559249},{"sourceId":193161758,"sourceType":"kernelVersion"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#数据链接\n#https://www.kaggle.com/competitions/rsna-2024-lumbar-spine-degenerative-classification\n#https://www.kaggle.com/datasets/namgalielei/ldsc-metadata\n#https://www.kaggle.com/code/namgalielei/lsdc-fold-split","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile scs_yolo_generate.py\nimport os\nimport pandas as pd\nimport numpy as np\nimport pydicom\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\nimport cv2\nimport glob\n\nIMG_DIR = \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images\"\n\nFOLDS = [0,1]\nOD_INPUT_SIZE = 768\nSTD_BOX_SIZE = 56\nSAMPLE = None\nCONDITIONS = ['Spinal Canal Stenosis']\nSEVERITIES = ['Normal/Mild', 'Moderate', 'Severe']\nLEVELS = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\n\n# rm -rf val_fold0\n\ntrain_val_df = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv')\ntrain_xy = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv')\ntrain_des = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv')\n\nif SAMPLE:\n    train_val_df = train_val_df.sample(SAMPLE, random_state=2698)\n\nfold_df = pd.read_csv('/kaggle/input/lsdc-fold-split/5folds.csv')\n\ntrain_xy.head(3)\n\ndef get_level(text):\n    for lev in ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']:\n        if lev in text:\n            split = lev.split('_')\n            split[0] = split[0].capitalize()\n            split[1] = split[1].capitalize()\n            return '/'.join(split)\n    raise ValueError('Level not found '+ lev)\n    \ndef get_condition(text):\n    split = text.split('_')\n    for i in range(len(split)):\n        split[i] = split[i].capitalize()\n    split = split[:-2]\n    return ' '.join(split)\n#     raise ValueError('Condition not found '+ lev)\n\ntrain_xy['condition'].unique()\n\n# train_df = train_df.dropna()\n\nlabel_df = {'study_id':[], 'condition': [], 'level':[], 'label':[]}\n\nfor i, row in train_val_df.iterrows():\n    study_id = row['study_id']\n    for k, label in row.iloc[1:].to_dict().items():\n        level = get_level(k)\n        condition = get_condition(k)\n        label_df['study_id'].append(study_id)\n        label_df['condition'].append(condition)\n        label_df['level'].append(level)\n        label_df['label'].append(label)\n#         break\n#     break\n\nlabel_df = pd.DataFrame(label_df)\nlabel_df = label_df.merge(fold_df, on='study_id')\n\ntrain_xy = train_xy.merge(train_des, how='inner', on=['study_id', 'series_id'])\nlabel_df = label_df.merge(train_xy, how='inner', on=['study_id', 'condition', 'level'])\n\n# label_df[label_df.series_id.isna()]\n\n# cnt = train_xy.groupby(['study_id', 'series_id', 'instance_number'])['condition'].nunique()\n\n# cnt[cnt>1]\n\ndef query_train_xy_row(study_id, series_id=None, instance_num=None):\n    if series_id is not None and instance_num is not None:\n        return label_df[(label_df.study_id==study_id) & (label_df.series_id==series_id) &\n            (label_df.instance_number==instance_num)]\n    elif series_id is None and instance_num is None:\n        return label_df[(label_df.study_id==study_id)]\n    else:\n        return label_df[(train_xy.study_id==study_id) & (label_df.series_id==series_id)]\n\n# import os\n\n# def count_dcm_files(directory):\n#     dcm_count = 0\n#     for root, dirs, files in os.walk(directory):\n#         for file in files:\n#             if file.endswith('.dcm'):\n#                 dcm_count += 1\n#     return dcm_count\n\n# dcm_files_count = count_dcm_files(IMG_DIR)\n\n# print(f\"Number of .dcm files: {dcm_files_count}\")\n\ndef read_dcm(src_path):\n    dicom_data = pydicom.dcmread(src_path)\n    image = dicom_data.pixel_array\n    image = (image - image.min()) / (image.max() - image.min() +1e-6) * 255\n    image = np.stack([image]*3, axis=-1).astype('uint8')\n    return image\n\ndef get_accronym(text):\n    split = text.split(' ')\n    return ''.join([x[0] for x in split])\n\n# study_id = 4003253 \n# series_id = 2448190387\n# instance_num = 28\n\nex = label_df.sample(1).iloc[0]\nstudy_id = ex.study_id\nseries_id = ex.series_id\ninstance_num = ex.instance_number\n\nWIDTH = 10\n\npath = os.path.join(IMG_DIR, str(study_id), str(series_id), f'{instance_num}.dcm')\n\nimg = read_dcm(path)\n\ntmp_df = query_train_xy_row(study_id, series_id, instance_num)\nfor i, row in tmp_df.iterrows():\n    lbl = f\"{get_accronym(row['condition'])}_{row['level']}\"\n    x, y = row['x'], row['y']\n    x1 = int(x - WIDTH)\n    x2 = int(x + WIDTH)\n    y1 = int(y - WIDTH)\n    y2 = int(y + WIDTH)\n    color = None\n    if row['label'] == 'Normal/Mild':\n        color =  (0, 255, 0)\n    elif row['label'] == 'Moderate':\n        color = (255,255,0) \n    elif row['label'] == 'Severe':\n        color = (255,0,0)\n        \n    fontFace = cv2.FONT_HERSHEY_SIMPLEX\n    fontScale = 0.5\n    thickness = 1\n    cv2.rectangle(img, (x1,y1), (x2,y2), color, 2)\n    cv2.putText(img, lbl, (x1,y1), fontFace, fontScale, color, thickness, cv2.LINE_AA)\n\ntmp_df\n\nplt.imshow(img)\nplt.show()\n\n# label_df[['study_id', 'series_id']].drop_duplicates()\n\ndef read_dcm(src_path):\n    dicom_data = pydicom.dcmread(src_path)\n    image = dicom_data.pixel_array\n    image = (image - image.min()) / (image.max() - image.min() +1e-6) * 255\n    image = np.stack([image]*3, axis=-1).astype('uint8')\n    return image\n\nfiltered_df = label_df[label_df.condition.map(lambda x: x in CONDITIONS)]\n\nlabel2id = {}\nid2label = {}\ni = 0\nfor cond in CONDITIONS:\n    for level in LEVELS:\n        for severity in SEVERITIES:\n            cls_ = f\"{cond.lower().replace(' ', '_')}_{level}_{severity.lower()}\"\n            label2id[cls_] = i\n            id2label[i] = cls_\n            i+=1\n\nid2label\n\ndef gen_yolo_format(ann_df, phase='train'):\n    for name, group in tqdm(ann_df.groupby(['study_id', 'series_id', 'instance_number'])):\n        study_id, series_id, instance_num = name[0], name[1], name[2]\n        path = f'{IMG_DIR}/{study_id}/{series_id}/{instance_num}.dcm'\n        img = read_dcm(path)\n        H, W = img.shape[:2]\n\n        img_dir = os.path.join(OUT_DIR, 'images', phase)\n        os.makedirs(img_dir, exist_ok=True)\n        img_path = os.path.join(img_dir, f'{study_id}_{series_id}_{instance_num}.jpg')\n        cv2.imwrite(img_path, img)\n\n        ann_dir = os.path.join(OUT_DIR, 'labels', phase)\n        os.makedirs(ann_dir, exist_ok=True)\n        ann_path = os.path.join(ann_dir, f'{study_id}_{series_id}_{instance_num}.txt')\n        if \"Severe\" in group[\"label\"].tolist():\n            group=group[group[\"label\"]==\"Severe\"].reset_index(drop=True)\n        with open(ann_path, 'w') as f:\n            for i, row in group.iterrows():\n                cond = row['condition']\n                level = row['level']\n                severity = row['label']\n                class_label = f\"{cond.lower().replace(' ', '_')}_{level.lower().replace('/', '_')}_{severity.lower()}\"\n                class_id = label2id[class_label]\n                x_center = row['x'] / W\n                y_center = row['y'] / H\n                width = W / OD_INPUT_SIZE * STD_BOX_SIZE / W\n                height = H /  OD_INPUT_SIZE * STD_BOX_SIZE / H\n                f.write(f'{class_id} {x_center} {y_center} {width} {height}\\n')\n\n#         break\n\nfor FOLD in FOLDS:\n    print('Gen data fold', FOLD)\n    OUT_DIR = f'data_fold{FOLD}'\n    os.makedirs(OUT_DIR, exist_ok=True)\n    \n    train_df = filtered_df[filtered_df.fold != FOLD]\n    val_df = filtered_df[filtered_df.fold == FOLD]\n    \n    gen_yolo_format(train_df, phase='train')\n    gen_yolo_format(val_df, phase='val')","metadata":{"_uuid":"764c284e-5e10-4726-a430-4f7e215a7993","_cell_guid":"52d318ba-52cf-4f6a-abc2-cfa79746df42","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-13T07:12:22.353571Z","iopub.execute_input":"2024-09-13T07:12:22.354482Z","iopub.status.idle":"2024-09-13T07:12:22.401269Z","shell.execute_reply.started":"2024-09-13T07:12:22.354439Z","shell.execute_reply":"2024-09-13T07:12:22.400176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python scs_yolo_generate.py","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:12:22.403561Z","iopub.execute_input":"2024-09-13T07:12:22.403952Z","iopub.status.idle":"2024-09-13T07:17:50.16038Z","shell.execute_reply.started":"2024-09-13T07:12:22.403893Z","shell.execute_reply":"2024-09-13T07:17:50.158958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r -q scs_data_fold0.zip data_fold0\n\n!rm -rf data_fold0\n!zip -r -q scs_data_fold1.zip data_fold1\n\n!rm -rf data_fold1","metadata":{"_uuid":"764c284e-5e10-4726-a430-4f7e215a7993","_cell_guid":"52d318ba-52cf-4f6a-abc2-cfa79746df42","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-13T07:17:50.162266Z","iopub.execute_input":"2024-09-13T07:17:50.162773Z","iopub.status.idle":"2024-09-13T07:18:33.312807Z","shell.execute_reply.started":"2024-09-13T07:17:50.162721Z","shell.execute_reply":"2024-09-13T07:18:33.311202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile ss_yolo_generate.py\nimport os\nimport pandas as pd\nimport numpy as np\nimport pydicom\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\nimport cv2\nimport glob\n\nIMG_DIR = \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images\"\n\nFOLDS = [0,1]\nOD_INPUT_SIZE = 768\nSTD_BOX_SIZE = 56\nSAMPLE = None\nCONDITIONS = ['Left Subarticular Stenosis', 'Right Subarticular Stenosis']\nSEVERITIES = ['Normal/Mild', 'Moderate', 'Severe']\nLEVELS = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\n\n\n# rm -rf val_fold0\n\ntrain_val_df = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv')\ntrain_xy = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv')\ntrain_des = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv')\n\nif SAMPLE:\n    train_val_df = train_val_df.sample(SAMPLE, random_state=2698)\n\nfold_df = pd.read_csv('/kaggle/input/lsdc-fold-split/5folds.csv')\n\ntrain_xy.head(3)\n\ndef get_level(text):\n    for lev in ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']:\n        if lev in text:\n            split = lev.split('_')\n            split[0] = split[0].capitalize()\n            split[1] = split[1].capitalize()\n            return '/'.join(split)\n    raise ValueError('Level not found '+ lev)\n    \ndef get_condition(text):\n    split = text.split('_')\n    for i in range(len(split)):\n        split[i] = split[i].capitalize()\n    split = split[:-2]\n    return ' '.join(split)\n#     raise ValueError('Condition not found '+ lev)\n\ntrain_xy['condition'].unique()\n\n# train_df = train_df.dropna()\n\nlabel_df = {'study_id':[], 'condition': [], 'level':[], 'label':[]}\n\nfor i, row in train_val_df.iterrows():\n    study_id = row['study_id']\n    for k, label in row.iloc[1:].to_dict().items():\n        level = get_level(k)\n        condition = get_condition(k)\n        label_df['study_id'].append(study_id)\n        label_df['condition'].append(condition)\n        label_df['level'].append(level)\n        label_df['label'].append(label)\n#         break\n#     break\n\nlabel_df = pd.DataFrame(label_df)\nlabel_df = label_df.merge(fold_df, on='study_id')\n\ntrain_xy = train_xy.merge(train_des, how='inner', on=['study_id', 'series_id'])\nlabel_df = label_df.merge(train_xy, how='inner', on=['study_id', 'condition', 'level'])\n\n# cnt[cnt>1]\n\ndef query_train_xy_row(study_id, series_id=None, instance_num=None):\n    if series_id is not None and instance_num is not None:\n        return label_df[(label_df.study_id==study_id) & (label_df.series_id==series_id) &\n            (label_df.instance_number==instance_num)]\n    elif series_id is None and instance_num is None:\n        return label_df[(label_df.study_id==study_id)]\n    else:\n        return label_df[(train_xy.study_id==study_id) & (label_df.series_id==series_id)]\n\n# import os\n\n# def count_dcm_files(directory):\n#     dcm_count = 0\n#     for root, dirs, files in os.walk(directory):\n#         for file in files:\n#             if file.endswith('.dcm'):\n#                 dcm_count += 1\n#     return dcm_count\n\n# dcm_files_count = count_dcm_files(IMG_DIR)\n\n# print(f\"Number of .dcm files: {dcm_files_count}\")\n\ndef read_dcm(src_path):\n    dicom_data = pydicom.dcmread(src_path)\n    image = dicom_data.pixel_array\n    image = (image - image.min()) / (image.max() - image.min() +1e-6) * 255\n    image = np.stack([image]*3, axis=-1).astype('uint8')\n    return image\n\ndef get_accronym(text):\n    split = text.split(' ')\n    return ''.join([x[0] for x in split])\n\n# study_id = 4003253 \n# series_id = 2448190387\n# instance_num = 28\n\nex = label_df.sample(1).iloc[0]\nstudy_id = ex.study_id\nseries_id = ex.series_id\ninstance_num = ex.instance_number\n\nWIDTH = 10\n\npath = os.path.join(IMG_DIR, str(study_id), str(series_id), f'{instance_num}.dcm')\n\nimg = read_dcm(path)\n\ntmp_df = query_train_xy_row(study_id, series_id, instance_num)\nfor i, row in tmp_df.iterrows():\n    lbl = f\"{get_accronym(row['condition'])}_{row['level']}\"\n    x, y = row['x'], row['y']\n    x1 = int(x - WIDTH)\n    x2 = int(x + WIDTH)\n    y1 = int(y - WIDTH)\n    y2 = int(y + WIDTH)\n    color = None\n    if row['label'] == 'Normal/Mild':\n        color =  (0, 255, 0)\n    elif row['label'] == 'Moderate':\n        color = (255,255,0) \n    elif row['label'] == 'Severe':\n        color = (255,0,0)\n        \n    fontFace = cv2.FONT_HERSHEY_SIMPLEX\n    fontScale = 0.5\n    thickness = 1\n    cv2.rectangle(img, (x1,y1), (x2,y2), color, 2)\n    cv2.putText(img, lbl, (x1,y1), fontFace, fontScale, color, thickness, cv2.LINE_AA)\n\ntmp_df\n\nplt.imshow(img)\nplt.show()\n\n# label_df[['study_id', 'series_id']].drop_duplicates()\n\ndef read_dcm(src_path):\n    dicom_data = pydicom.dcmread(src_path)\n    image = dicom_data.pixel_array\n    image = (image - image.min()) / (image.max() - image.min() +1e-6) * 255\n    image = np.stack([image]*3, axis=-1).astype('uint8')\n    return image\n\nfiltered_df = label_df[label_df.condition.map(lambda x: x in CONDITIONS)]\n\nlabel2id = {}\nid2label = {}\ni = 0\nfor cond in CONDITIONS:\n    for level in LEVELS:\n        for severity in SEVERITIES:\n            cls_ = f\"{cond.lower().replace(' ', '_')}_{level}_{severity.lower()}\"\n            label2id[cls_] = i\n            id2label[i] = cls_\n            i+=1\n\nid2label\n\ndef gen_yolo_format(ann_df, phase='train'):\n    for name, group in tqdm(ann_df.groupby(['study_id', 'series_id', 'instance_number'])):\n        study_id, series_id, instance_num = name[0], name[1], name[2]\n        path = f'{IMG_DIR}/{study_id}/{series_id}/{instance_num}.dcm'\n        img = read_dcm(path)\n        H, W = img.shape[:2]\n\n        img_dir = os.path.join(OUT_DIR, 'images', phase)\n        os.makedirs(img_dir, exist_ok=True)\n        img_path = os.path.join(img_dir, f'{study_id}_{series_id}_{instance_num}.jpg')\n        cv2.imwrite(img_path, img)\n\n        ann_dir = os.path.join(OUT_DIR, 'labels', phase)\n        os.makedirs(ann_dir, exist_ok=True)\n        ann_path = os.path.join(ann_dir, f'{study_id}_{series_id}_{instance_num}.txt')\n        if \"Severe\" in group[\"label\"].tolist():\n            group=group[group[\"label\"]==\"Severe\"].reset_index(drop=True)\n        contain_nulls = False\n        \n        with open(ann_path, 'w') as f:\n            for i, row in group.iterrows():\n                cond = row['condition']\n                level = row['level']\n                severity = row['label']\n                if pd.isnull(severity):\n                    contain_nulls = True\n                    break\n                class_label = f\"{cond.lower().replace(' ', '_')}_{level.lower().replace('/', '_')}_{severity.lower()}\"\n                class_id = label2id[class_label]\n                x_center = row['x'] / W\n                y_center = row['y'] / H\n                width = W / OD_INPUT_SIZE * STD_BOX_SIZE / W\n                height = H /  OD_INPUT_SIZE * STD_BOX_SIZE / H\n                f.write(f'{class_id} {x_center} {y_center} {width} {height}\\n')\n        \n        if not contain_nulls:\n            cv2.imwrite(img_path, img)\n#         break\n\nfor FOLD in FOLDS:\n    print('Gen data fold', FOLD)\n    OUT_DIR = f'data_fold{FOLD}'\n    os.makedirs(OUT_DIR, exist_ok=True)\n    \n    train_df = filtered_df[filtered_df.fold != FOLD]\n    val_df = filtered_df[filtered_df.fold == FOLD]\n    \n    gen_yolo_format(train_df, phase='train')\n    gen_yolo_format(val_df, phase='val')\n\n","metadata":{"_uuid":"764c284e-5e10-4726-a430-4f7e215a7993","_cell_guid":"52d318ba-52cf-4f6a-abc2-cfa79746df42","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-13T07:24:40.968535Z","iopub.execute_input":"2024-09-13T07:24:40.969077Z","iopub.status.idle":"2024-09-13T07:24:40.985191Z","shell.execute_reply.started":"2024-09-13T07:24:40.969032Z","shell.execute_reply":"2024-09-13T07:24:40.983994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python ss_yolo_generate.py","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:24:41.995127Z","iopub.execute_input":"2024-09-13T07:24:41.995634Z","iopub.status.idle":"2024-09-13T07:50:56.942834Z","shell.execute_reply.started":"2024-09-13T07:24:41.995596Z","shell.execute_reply":"2024-09-13T07:50:56.940924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r -q ss_data_fold0.zip data_fold0\n!rm -rf data_fold0\n!zip -r -q ss_data_fold1.zip data_fold1\n!rm -rf data_fold1","metadata":{"execution":{"iopub.status.busy":"2024-09-13T08:05:30.292746Z","iopub.execute_input":"2024-09-13T08:05:30.293263Z","iopub.status.idle":"2024-09-13T08:10:57.408207Z","shell.execute_reply.started":"2024-09-13T08:05:30.293217Z","shell.execute_reply":"2024-09-13T08:10:57.406456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile nfn_yolo_generate.py\nimport os\nimport pandas as pd\nimport numpy as np\nimport pydicom\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\nimport cv2\nimport glob\n\nIMG_DIR = \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images\"\n\nFOLDS = [0,1]\nOD_INPUT_SIZE = 768\nSTD_BOX_SIZE = 56\nSAMPLE = None\nCONDITIONS = ['Left Neural Foraminal Narrowing', 'Right Neural Foraminal Narrowing']\nSEVERITIES = ['Normal/Mild', 'Moderate', 'Severe']\nLEVELS = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\n\n# rm -rf val_fold0\n\ntrain_val_df = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv')\ntrain_xy = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv')\ntrain_des = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv')\n\nif SAMPLE:\n    train_val_df = train_val_df.sample(SAMPLE, random_state=2698)\n\nfold_df = pd.read_csv('/kaggle/input/lsdc-fold-split/5folds.csv')\n\ntrain_xy.head(3)\n\ndef get_level(text):\n    for lev in ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']:\n        if lev in text:\n            split = lev.split('_')\n            split[0] = split[0].capitalize()\n            split[1] = split[1].capitalize()\n            return '/'.join(split)\n    raise ValueError('Level not found '+ lev)\n    \ndef get_condition(text):\n    split = text.split('_')\n    for i in range(len(split)):\n        split[i] = split[i].capitalize()\n    split = split[:-2]\n    return ' '.join(split)\n#     raise ValueError('Condition not found '+ lev)\n\ntrain_xy['condition'].unique()\n\n# train_df = train_df.dropna()\n\nlabel_df = {'study_id':[], 'condition': [], 'level':[], 'label':[]}\n\nfor i, row in train_val_df.iterrows():\n    study_id = row['study_id']\n    for k, label in row.iloc[1:].to_dict().items():\n        level = get_level(k)\n        condition = get_condition(k)\n        label_df['study_id'].append(study_id)\n        label_df['condition'].append(condition)\n        label_df['level'].append(level)\n        label_df['label'].append(label)\n#         break\n#     break\n\nlabel_df = pd.DataFrame(label_df)\nlabel_df = label_df.merge(fold_df, on='study_id')\n\ntrain_xy = train_xy.merge(train_des, how='inner', on=['study_id', 'series_id'])\nlabel_df = label_df.merge(train_xy, how='inner', on=['study_id', 'condition', 'level'])\n\n# label_df[label_df.series_id.isna()]\n\n# cnt = train_xy.groupby(['study_id', 'series_id', 'instance_number'])['condition'].nunique()\n\n# cnt[cnt>1]\n\ndef query_train_xy_row(study_id, series_id=None, instance_num=None):\n    if series_id is not None and instance_num is not None:\n        return label_df[(label_df.study_id==study_id) & (label_df.series_id==series_id) &\n            (label_df.instance_number==instance_num)]\n    elif series_id is None and instance_num is None:\n        return label_df[(label_df.study_id==study_id)]\n    else:\n        return label_df[(train_xy.study_id==study_id) & (label_df.series_id==series_id)]\n\n# import os\n\n# def count_dcm_files(directory):\n#     dcm_count = 0\n#     for root, dirs, files in os.walk(directory):\n#         for file in files:\n#             if file.endswith('.dcm'):\n#                 dcm_count += 1\n#     return dcm_count\n\n# dcm_files_count = count_dcm_files(IMG_DIR)\n\n# print(f\"Number of .dcm files: {dcm_files_count}\")\n\ndef read_dcm(src_path):\n    dicom_data = pydicom.dcmread(src_path)\n    image = dicom_data.pixel_array\n    image = (image - image.min()) / (image.max() - image.min() +1e-6) * 255\n    image = np.stack([image]*3, axis=-1).astype('uint8')\n    return image\n\ndef get_accronym(text):\n    split = text.split(' ')\n    return ''.join([x[0] for x in split])\n\n# study_id = 4003253 \n# series_id = 2448190387\n# instance_num = 28\n\nex = label_df.sample(1).iloc[0]\nstudy_id = ex.study_id\nseries_id = ex.series_id\ninstance_num = ex.instance_number\n\nWIDTH = 10\n\npath = os.path.join(IMG_DIR, str(study_id), str(series_id), f'{instance_num}.dcm')\n\nimg = read_dcm(path)\n\ntmp_df = query_train_xy_row(study_id, series_id, instance_num)\nfor i, row in tmp_df.iterrows():\n    lbl = f\"{get_accronym(row['condition'])}_{row['level']}\"\n    x, y = row['x'], row['y']\n    x1 = int(x - WIDTH)\n    x2 = int(x + WIDTH)\n    y1 = int(y - WIDTH)\n    y2 = int(y + WIDTH)\n    color = None\n    if row['label'] == 'Normal/Mild':\n        color =  (0, 255, 0)\n    elif row['label'] == 'Moderate':\n        color = (255,255,0) \n    elif row['label'] == 'Severe':\n        color = (255,0,0)\n        \n    fontFace = cv2.FONT_HERSHEY_SIMPLEX\n    fontScale = 0.5\n    thickness = 1\n    cv2.rectangle(img, (x1,y1), (x2,y2), color, 2)\n    cv2.putText(img, lbl, (x1,y1), fontFace, fontScale, color, thickness, cv2.LINE_AA)\n\ntmp_df\n\nplt.imshow(img)\nplt.show()\n\n# label_df[['study_id', 'series_id']].drop_duplicates()\n\ndef read_dcm(src_path):\n    dicom_data = pydicom.dcmread(src_path)\n    image = dicom_data.pixel_array\n    image = (image - image.min()) / (image.max() - image.min() +1e-6) * 255\n    image = np.stack([image]*3, axis=-1).astype('uint8')\n    return image\n\nfiltered_df = label_df[label_df.condition.map(lambda x: x in CONDITIONS)]\n\nlabel2id = {}\nid2label = {}\ni = 0\nfor cond in CONDITIONS:\n    for level in LEVELS:\n        for severity in SEVERITIES:\n            cls_ = f\"{cond.lower().replace(' ', '_')}_{level}_{severity.lower()}\"\n            label2id[cls_] = i\n            id2label[i] = cls_\n            i+=1\n\nid2label\n\ndef gen_yolo_format(ann_df, phase='train'):\n    for name, group in tqdm(ann_df.groupby(['study_id', 'series_id', 'instance_number'])):\n        study_id, series_id, instance_num = name[0], name[1], name[2]\n        path = f'{IMG_DIR}/{study_id}/{series_id}/{instance_num}.dcm'\n        img = read_dcm(path)\n        H, W = img.shape[:2]\n\n        img_dir = os.path.join(OUT_DIR, 'images', phase)\n        os.makedirs(img_dir, exist_ok=True)\n        img_path = os.path.join(img_dir, f'{study_id}_{series_id}_{instance_num}.jpg')\n        cv2.imwrite(img_path, img)\n\n        ann_dir = os.path.join(OUT_DIR, 'labels', phase)\n        os.makedirs(ann_dir, exist_ok=True)\n        ann_path = os.path.join(ann_dir, f'{study_id}_{series_id}_{instance_num}.txt')\n        \n        contain_nulls = False\n        if \"Severe\" in group[\"label\"].tolist():\n            group=group[group[\"label\"]==\"Severe\"].reset_index(drop=True)\n        with open(ann_path, 'w') as f:\n            for i, row in group.iterrows():\n                cond = row['condition']\n                level = row['level']\n                severity = row['label']\n                if pd.isnull(severity):\n                    contain_nulls = True\n                    break\n                class_label = f\"{cond.lower().replace(' ', '_')}_{level.lower().replace('/', '_')}_{severity.lower()}\"\n                class_id = label2id[class_label]\n                x_center = row['x'] / W\n                y_center = row['y'] / H\n                width = W / OD_INPUT_SIZE * STD_BOX_SIZE / W\n                height = H /  OD_INPUT_SIZE * STD_BOX_SIZE / H\n                f.write(f'{class_id} {x_center} {y_center} {width} {height}\\n')\n        \n        if not contain_nulls:\n            cv2.imwrite(img_path, img)\n#         break\n\nfor FOLD in FOLDS:\n    print('Gen data fold', FOLD)\n    OUT_DIR = f'data_fold{FOLD}'\n    os.makedirs(OUT_DIR, exist_ok=True)\n    \n    train_df = filtered_df[filtered_df.fold != FOLD]\n    val_df = filtered_df[filtered_df.fold == FOLD]\n    \n    gen_yolo_format(train_df, phase='train')\n    gen_yolo_format(val_df, phase='val')\n\n","metadata":{"_uuid":"764c284e-5e10-4726-a430-4f7e215a7993","_cell_guid":"52d318ba-52cf-4f6a-abc2-cfa79746df42","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-13T08:10:57.412043Z","iopub.execute_input":"2024-09-13T08:10:57.412475Z","iopub.status.idle":"2024-09-13T08:10:57.429336Z","shell.execute_reply.started":"2024-09-13T08:10:57.41243Z","shell.execute_reply":"2024-09-13T08:10:57.428019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python nfn_yolo_generate.py","metadata":{"execution":{"iopub.status.busy":"2024-09-13T08:10:57.430647Z","iopub.execute_input":"2024-09-13T08:10:57.431039Z","iopub.status.idle":"2024-09-13T08:31:06.748619Z","shell.execute_reply.started":"2024-09-13T08:10:57.431007Z","shell.execute_reply":"2024-09-13T08:31:06.744608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r -q nfn_data_fold0.zip data_fold0\n!rm -rf data_fold0\n!zip -r -q nfn_data_fold1.zip data_fold1\n!rm -rf data_fold1","metadata":{"execution":{"iopub.status.busy":"2024-09-13T08:41:13.949698Z","iopub.execute_input":"2024-09-13T08:41:13.950253Z","iopub.status.idle":"2024-09-13T08:43:14.088742Z","shell.execute_reply.started":"2024-09-13T08:41:13.950209Z","shell.execute_reply":"2024-09-13T08:43:14.087004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -r /kaggle/working/*.py","metadata":{"execution":{"iopub.status.busy":"2024-09-13T08:44:51.657685Z","iopub.execute_input":"2024-09-13T08:44:51.658251Z","iopub.status.idle":"2024-09-13T08:44:52.815889Z","shell.execute_reply.started":"2024-09-13T08:44:51.658206Z","shell.execute_reply":"2024-09-13T08:44:52.814113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
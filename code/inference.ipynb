{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"},{"sourceId":9569239,"sourceType":"datasetVersion","datasetId":5832599},{"sourceId":193417638,"sourceType":"kernelVersion"},{"sourceId":199443794,"sourceType":"kernelVersion"},{"sourceId":199685628,"sourceType":"kernelVersion"},{"sourceId":199815084,"sourceType":"kernelVersion"},{"sourceId":199849132,"sourceType":"kernelVersion"}],"dockerImageVersionId":30747,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q --no-index --find-links /kaggle/input/ultralytics ultralytics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile convert_img.py \n\nimport os\nimport pydicom\nfrom PIL import Image\nimport numpy as np\nfrom multiprocessing import Pool, cpu_count\n\nimport sklearn.metrics\nimport torch\nimport cv2\nimport numpy as np \nimport pandas as pd \nfrom tqdm.auto import tqdm\nIMG_DIR = '/images'\ndef read_dcm(src_path):\n    dicom_data = pydicom.dcmread(src_path)\n    image = dicom_data.pixel_array\n    image = (image - image.min()) / (image.max() - image.min() +1e-6) * 255\n    return image\n\ndef convert_dcm_to_jpg(file_path):\n    try:\n        # Read the DICOM file\n        image_array = read_dcm(file_path)\n        \n        # Define the output path\n        relative_path = os.path.relpath(file_path, start=input_directory)\n        output_path = os.path.join(output_directory, relative_path)\n        output_path = output_path.replace('.dcm', '.jpg')\n                \n        # Create the output directory if it doesn't exist\n        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n        \n        # Save the image as a JPEG file\n        cv2.imwrite(output_path, image_array)\n        \n        return output_path\n    except Exception as e:\n        print(f\"Error processing file {file_path}: {e}\")\n        return None\n\ndef process_files(dcm_files):\n    with Pool(cpu_count()) as pool:\n        # Wrap pool.map with tqdm to show the progress bar\n        list(tqdm(pool.imap(convert_dcm_to_jpg, dcm_files), total=len(dcm_files)))\n\ndef get_dcm_files(directory):\n    dcm_files = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if file.endswith('.dcm'):\n                dcm_files.append(os.path.join(root, file))\n    return dcm_files    \n\n\ninput_directory = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images'\n\noutput_directory = IMG_DIR\n\n# Get all .dcm files in the input directory\ndcm_files = get_dcm_files(input_directory)\n\n# Process the files using multiprocessing\nprocess_files(dcm_files)\n\nprint(f\"Conversion completed. Images saved to {output_directory}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python convert_img.py ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile infer.py \n\nimport sys\nmodel_dir = sys.argv[1]\nimg_size = int(sys.argv[2])\nfold_index = int(sys.argv[3])\nsave_file = sys.argv[4]\n#weight = sys.argv[5]\nprint(model_dir, img_size, fold_index)\n\nimport os\nimport pydicom\nfrom PIL import Image\nimport numpy as np\nfrom multiprocessing import Pool, cpu_count\n\nimport sklearn.metrics\nimport torch\nimport cv2\nimport numpy as np \nimport pandas as pd \nfrom tqdm.auto import tqdm\n\nEVAL = 0 \nIMG_DIR = '/images'\nFOLD = int(fold_index)\nSAMPLE = 0 \nSEVERITIES = ['Normal/Mild', 'Moderate', 'Severe']\nLEVELS = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\n\nSCS_WEIGHTS = [f'{model_dir}/scs_fold{FOLD}_{img_size}_normal.pt']\nSS_WEIGHTS = [f'{model_dir}/ss_fold{FOLD}_{img_size}_normal.pt']\nNFN_WEIGHTS = [f'{model_dir}/nfn_fold{FOLD}_{img_size}_normal.pt']\n\nSCS_WEIGHTS += [f'{model_dir}/scs_fold{FOLD}_{img_size}_severe.pt']\nSS_WEIGHTS += [f'{model_dir}/ss_fold{FOLD}_{img_size}_severe.pt']\nNFN_WEIGHTS += [f'{model_dir}/nfn_fold{FOLD}_{img_size}_severe.pt']\n\nprint(SCS_WEIGHTS,'\\n', SS_WEIGHTS,'\\n', NFN_WEIGHTS)\n\ntrain_val_df = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv')\ndes = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv')\n\n\ntest_df = os.listdir('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images')\ntest_df = pd.DataFrame(test_df, columns=['study_id'])\ntest_df['study_id'] = test_df['study_id'].astype(int)\n    \ntest_df = test_df.merge(des, on=['study_id'])\n\ndef gen_label_map(CONDITIONS):\n    label2id = {}\n    id2label = {}\n    i = 0\n    for cond in CONDITIONS:\n        for level in LEVELS:\n            for severity in SEVERITIES:\n                cls_ = f\"{cond.lower().replace(' ', '_')}_{level}_{severity.lower()}\"\n                label2id[cls_] = i\n                id2label[i] = cls_\n                i+=1\n    return label2id, id2label\n                \nscs_label2id, scs_id2label = gen_label_map(['Spinal Canal Stenosis'])\nss_label2id, ss_id2label = gen_label_map(['Left Subarticular Stenosis', 'Right Subarticular Stenosis'])\nnfn_label2id, nfn_id2label = gen_label_map(['Left Neural Foraminal Narrowing', 'Right Neural Foraminal Narrowing'])\n\nfrom ultralytics import YOLO\n\n# Load YOLO Model\nscs_models = []\nfor weight in SCS_WEIGHTS:\n    scs_models.append(YOLO(weight))\n\nss_models = []\nfor weight in SS_WEIGHTS:\n    ss_models.append(YOLO(weight))\n\nnfn_models = []\nfor weight in NFN_WEIGHTS:\n    nfn_models.append(YOLO(weight))\n\nall_label_set = train_val_df.iloc[0, 1:].index.tolist()\nscs_label_set = all_label_set[:5]\nnfn_label_set = all_label_set[5:15]\nss_label_set = all_label_set[15:]\n\nsettings = [\n    ( 'Sagittal T2/STIR', scs_models, scs_id2label, scs_label_set, 0.01),\n    ( 'Axial T2', ss_models, ss_id2label, ss_label_set, 0.02),\n    ( 'Sagittal T1', nfn_models, nfn_id2label, nfn_label_set, 0.02)\n]\n\nfrom collections import defaultdict\n\npred_rows = []\n\nfor modality, models, id2label, label_set, thresh in settings:\n    mod_df = test_df[test_df.series_description == modality]\n    \n    if SAMPLE:\n        mod_df = mod_df.sample(20, random_state=610)\n    \n    # for each study, at each level and condition, get the maximum probability score\n    for study_id, group in tqdm(mod_df.groupby('study_id')):\n        predictions = defaultdict(list)\n        for i, row in group.iterrows():\n            # predict on all images from all the series\n            series_dir = os.path.join(IMG_DIR, str(row['study_id']), str(row['series_id']))\n            for model in models:\n                results = model(series_dir, imgsz=img_size, conf=thresh, verbose=False, augment=False, )\n                for res in results:\n                    for pred_class, conf in zip(res.boxes.cls, res.boxes.conf):\n                        pred_class = pred_class.item()\n                        conf = conf.item()\n                        _class = id2label[pred_class]\n                        predictions[_class].append(conf)\n        \n        # aggregate the result on images to obtain study-level prediction\n        for condition in label_set:\n            res_dict = {'row_id': f'{study_id}_{condition}' }\n\n            score_vec = []\n            for severity in SEVERITIES:\n                if severity=='Severe':\n                    scaler = 1.8\n                elif severity=='Moderate':\n                    scaler = 1.2\n                else:\n                    scaler = 0.8488\n                severity = severity.lower()\n                key = f'{condition}_{severity}'\n                if len(predictions[key]) > 0:\n                    score = np.max(predictions[key])\n                else:\n                    score = thresh\n                    \n                if score>0.2:\n                    score = score*scaler\n                    \n                score_vec.append(score)\n                \n            # normalize score to sum to 1\n            score_vec = torch.tensor(score_vec)\n            score_vec = score_vec / score_vec.sum()\n\n            for idx, severity in enumerate(SEVERITIES):\n                res_dict[severity.replace('/', '_').lower()] = score_vec[idx].item()\n\n            pred_rows.append(res_dict)\n\n\npred_df = pd.DataFrame(pred_rows)\npred_df\n\npred_df.to_csv(save_file, index=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python infer.py /kaggle/input/rsna2024-yolov8l 384 1 pred1.csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python infer.py /kaggle/input/rsna2024-yolov8l 512 1 pred2.csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python infer.py /kaggle/input/rsna2024-yolov8l 768 1 pred3.csv","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nimport pandas as pd\nsubs = glob.glob('/kaggle/working/pred*.csv')\npreds = []\nfor f in subs:\n    df = pd.read_csv(f)\n    preds.append(df)\n\npreds = pd.concat(preds, ignore_index=True)\n\npreds = preds.groupby(['row_id']).agg({'normal_mild':\"mean\", 'moderate':\"mean\", 'severe':\"mean\"}).sort_index().reset_index()\npreds.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}